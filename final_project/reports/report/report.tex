%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Wenneker Article
% LaTeX Template
% Version 2.0 (28/2/17)
%
% This template was downloaded from:
% http://www.LaTeXTemplates.com
%
% Authors:
% Vel (vel@LaTeXTemplates.com)
% Frits Wenneker
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[10pt, a4paper, twocolumn]{article} % 10pt font size (11 and 12 also possible), A4 paper (letterpaper for US letter) and two column layout (remove for one column)

\input{structure.tex} % Specifies the document structure and loads requires packages

%----------------------------------------------------------------------------------------
%	ARTICLE INFORMATION
%----------------------------------------------------------------------------------------

\title{Effective Methods for Capturing Cattle Rustlers} % The article title

\author{
	\authorstyle{Yung-Hsin Chen\textsuperscript{1} and Haoxin Cai\textsuperscript{1}} % Authors
	\newline\newline % Space before institutions
	\textsuperscript{1}\institution{Universit{\"a}t Z{\"u}rich, Z{\"u}rich, Switzerland} % Institution 1
}

% Example of a one line author/institution relationship
%\author{\newauthor{John Marston} \newinstitution{Universidad Nacional Autónoma de México, Mexico City, Mexico}}

\date{19 December 2022} % Add a date here if you would like one to appear underneath the title block, use \today for the current date, leave empty for no date

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Print the title

\thispagestyle{firstpage} % Apply the page style for the first page (no headers and footers)

%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

\lettrineabstract{The goal of the report is to get the most related factors of COVID-19 
pandemic cases in countries. In this report, data are collected from 192 countries, and classification 
models are applied in order to get a list of feature importance. It is believed that the more-important-features 
play more crucial role in the severity of the pandemic of a certain country. With an accuracy of 74.36\%, 
XGBoost model suggests that human development index, life expectancy, population density, 
hospital beds per thousand and GDP per capita of a country are the leading factors of the severity 
of the pandemic.}

%----------------------------------------------------------------------------------------
%	ARTICLE CONTENTS
%----------------------------------------------------------------------------------------

%----------------------------------------------------------------------------------------
%	INTRODUCTION
%----------------------------------------------------------------------------------------
\section{Introduction}The COVID-19 pandemic has severe impacts on almost every aspect around the world. 
It causes not only social and economic disruption, but also drastic death rates. Inevitably, people 
are curious about the causalities of COVID-19 and how to prevent the pandemic from getting worse. 
Therefore, the report aims to determine the correlation between the severity of the pandemic 
other information of a country. Notes that the time parameters are taken out of consideration for simplicity. 

%----------------------------------------------------------------------------------------
%	DOMAIN KNOWLEDGE
%----------------------------------------------------------------------------------------
\section{Domain Knowledge}\label{sec:domain_knowledge}

%----------------------------------------------------------------------------------------
%	METHOD
%----------------------------------------------------------------------------------------
\section{Method}
In this section, the methods of this particular task will be explained, including introduction of data, building 
features for the models, training and predicting classifiers and generating the feature importance table. 
Classifiers and other used tools are introduced and explained in \autoref{sec:domain_knowledge}.
\subsection{Data}
Data used for this task is from covid-19-data from Our World of Data. It is online in a github repository, making 
it easy to access. The data is loaded into the local database by the \emph{request} package of Python.\\[10pt]
The data consists of 67 columns and 248 countries with 236386 rows in total. Attribute \emph{location} and 
\emph{date} together define each unique row of data. The data is still being updated. 
A summary table of the data is shown 
in \autoref{tab:data_summary}.
\begin{table}
	\caption{Data Summary Table}
	\centering
	\begin{tabular}{lr}
		\toprule
		\textbf{Information} & \textbf{Description} \\
		\midrule
		number of columns & 67 \\
		number of rows & 236386 \\
		number of countries & 248 \\
		key & \{location:date\}\\
		starting date & 01.Jan.2020\\
		\bottomrule
	\label{tab:data_summary}
	\end{tabular}
\end{table}
\subsection{Building Features}
The process of building features includes data cleaning and feature selection, and label preparation. Data cleaning 
and feature selecting is crucial for the accuracy of models. Bad data cleaning can lead to biased results or 
bad model performances. Relevant attributes will be selected as features to be put into the classifiers, i.e., 
the models. Finally, since this is a supervised learning task, the label should be prepared for model training.\\[10pt]
In the data cleaning phase, the goal is to get a table of one row per country, i.e., each row represents the 
information of a country. The label is defined as the attribute, \emph{total\_cases\_per\_million}. To achieve this, 
relavent attributes are first selected for model training. For this task, eleven attributes that is speculated to 
affect the number of COVID cases are selected from the raw data. The selected attributes are listed in 
\autoref{tab:attributes}. Countries with less than 200 rows of data is then removed. Since each row corresponds 
to one date, it is not ideal to use the data of a country if less than 200 days of data are recorded. Among the 
selected attributes, \emph{aged\_65\_older} and \emph{aged\_70\_older} are divided by \emph{population} into 
\emph{aged\_65\_older\_percentage} and \emph{aged\_70\_older\_percentage} respectively so that the models are 
trained on the percentage of elder people instead of the total number. Except for the attribute 
\emph{people\_fully\_vaccinated\_per\_hundred}, all the other attributes have a single value throughout the dates 
for each country. However, the attribute \emph{people\_fully\_vaccinated\_per\_hundred} and the label attribute 
\emph{total\_cases\_per\_million} is accumulated day by day. In this case, the data of the latest date is used as 
the feature value for each country. By doing this, the model will be able to generate the feature importance 
table according to how all features affect the number of total cases per million in each country. After data 
cleaning and feature selection, 194 countries/rows and 11 features are left for model training.\\[10pt]
\begin{table}
	\caption{Data Summary Table}
	\centering
	\begin{tabular}{ll}
		\toprule
		\textbf{Selected Attributes} &  \\
		\midrule
		aged\_65\_older & cardiovasc\_death\_rate \\
		aged\_70\_older & diabetes\_prevalence \\
		gdp\_per\_capita & hospital\_beds\_per\_thousand \\
		population\_density & human\_development\_index \\
		life\_expectancy & median\_age \\
		\multicolumn{2}{l}{people\_fully\_vaccinated\_per\_hundred} \\
		\bottomrule
	\label{tab:attributes}
	\end{tabular}
\end{table}
After data cleaning and feature selection, label preparation is performed. The attribute \emph{total\_cases\_per\_million} 
is categorised into four levels of severity. The interval of the categorisation is shown in \autoref{tab:label_interval}. 
Apparently, there is no country with over 700'000 cases per million. 
\begin{table}
	\caption{Label Interval for Label Preparation}
	\centering
	\begin{tabular}{ll}
		\toprule
		\textbf{Level} & \textbf{Interval} \\
		\midrule
		0 & 0 - 50'000 \\
		1 & 50'000 - 200'000 \\
		2 & 200'000 - 400'000 \\
		3 & 400'000 - 700'000\\
		\bottomrule
	\label{tab:label_interval}
	\end{tabular}
\end{table}
[0, 50000, 200000, 400000, 700000]
\subsection{Classifiers}
Classifiers are used for classification tasks. Due to the small dimension of the dataset, several changes are made to 
adapt the data size. The data is not splitted into training, validation and testing datasets, but only training and 
testing only. In this task, the training-testing split will be 80\% and 20\% respectively. Besides, it is not recommended 
to use models with too many parameters since it might have to higher chance of overfitting. Thus, simple models are 
picked out for this task including logistic regression, linear perceptron and XGBoost. These models can be easily 
applied to the dataset with \emph{sklearn} from Python. For hyperparameter selection, grid search cross validation 
is used. A summary of models used for the task and the best performing hyperparameters chosen by applying grid search 
cross validation are listed out in \autoref{tab:model_summary}.
\begin{table}
	\caption{Model Summary}
	\centering
	\begin{tabular}{lr}
		\toprule
		\textbf{Model} & \textbf{Details} \\
		\toprule
		\textbf{Logistic Regression} & \\ 
		penalty & l2 \\
		solver & newton-cg \\
		\midrule
		\textbf{Linear Perceptron} & \\
		tolerance & 0.001 \\
		random state & 0 \\
		\midrule
		\textbf{XGBoost} & \\
		learning rate & 0.1\\
		loss & deviance \\
		max depth & 3 \\
		n\_estimators & 100 \\
		random state & 21 \\
	\bottomrule
	\label{tab:model_summary}
	\end{tabular}
\end{table}
\subsection{Feature Importance Table}
The feature importance is generated automatically via the trained model. It shows weight of each feature. The weight can 
be thought of as how significant each feature effects the classification accuracy. The more positive the feature importance 
score, the more the feature helps reduce the loss while training. However, if the feature importance is negative, the feature 
increases the loss while training.
\section{Results}
By applying the test dataset on the model, the performance of the models can be evaluated. The accuracy summary of each 
model and the feature importance table from the best performing model is shown in \autoref{tab:acc_summary} and 
\autoref{tab:feature_importance}. Among the models, XGBoost has the best performance.
\begin{table}
	\caption{Model Accuracy Summary}
	\centering
	\begin{tabular}{ll}
		\toprule
		\textbf{Model} & \textbf{Summary} \\
		\midrule
		Logistic Regression & 61.54\% \\
		Linear Perceptron & 48.72\% \\
		XGBoost & 74.36\% \\
		\bottomrule
	\label{tab:acc_summary}
	\end{tabular}
\end{table}
\begin{table}
	\caption{Feature Importance from XGBoost}
	\centering
	\begin{tabular}{lll}
		\toprule
		& \textbf{Feature} & \textbf{Importance} \\
		\midrule
		1&human\_development\_index & 0.462551 \\
		2& life\_expectancy& 0.462551\\
		3& population\_density& 0.138737\\
		4& hospital\_beds\_per\_thousand& 0.082238\\
		5& gdp\_per\_capita& 0.065485\\
		6& people\_fully\_vaccinated\_per\_hundred& 0.059118\\
		7& cardiovasc\_death\_rate& 0.045620\\
		8& aged\_70\_older\_percentage& 0.033860\\
		9& median\_age& 0.029610\\
		12& diabetes\_prevalence& 0.026468\\
		11& aged\_65\_older\_percentage& 0.025800\\
		\bottomrule
	\label{tab:feature_importance}
	\end{tabular}
\end{table}

\section{Dicussion}
\section{Conclusion}
%----------------------------------------------------------------------------------------
%	BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

\printbibliography[title={Bibliography}] % Print the bibliography, section title in curly brackets

%----------------------------------------------------------------------------------------

\end{document}
